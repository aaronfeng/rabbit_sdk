* settings

#+LINK: bug https://extra.lshift.net/bugzilla/show_bug.cgi?id=
#+TODO: TODO | WAITING | DONE

* to do
** client API

three layers 

We need this for .net initially, and Java at some later point

*** DONE standard RMQ client API
*** TODO reliable, available, asynchronous, point-to-point conversation API

in turn comprised of three sub-layers

**** TODO reliable connection/channel

at-least-once delivery in the presence of
- server and network failures
- sender and recipient failures 

- same api as normal connection/channel
- channels keeps track of
  - subscriptions
  - tx mode or checkpoint mode
  - qos prefetch
  - publishes since last commit/cancel / checkpoint, or during last n ms
    (depending on mode)
  - pending acks
- automatically reconnects in the event of errors that are not the
  client/app's fault
- on reconnect the channels are re-opened and for each channel
  - the tx/checkpoint mode is (re)selected
  - the qos prefetch is (re)set
  - subscriptions are recreated
  - buffered publishes are resent
- acks for messages delivered in a previous (i.e. not the current)
  session are silently dropped (or, rather, we drop all acks that
  aren't pending) - otherwise the server would reject
  them with an error
- callback to notify app when broker is deemed to have accepted
  responsibilty for a message. By persisting this info apps can limit
  the amount of resends they have to do in the event of a client
  failure.
- callbacks for connection and channel lifecycle events - invoked for
  connect, reconnect, disconnect and retry-exceeded events

props:
- reconnect/resend policy
  - retry_interval
  - exponential_backoff_steps
  - maximum retries
  - buffer_duration (keep outbound messages for n ms, in case resend
    is needed)

***** no replay of commands

The trouble with replaying commands is that we may stomp on resources
that have been created/deleted by other connections.

The other problem is that we do not know the state the system was in
at the beginning of the recording.

And, finally, some commands are not idempotent.

-> decision: we only keep track of publishes. Synchronous commands
fail in the event of a disconnect.

async commands issued during a disconnect are silently dropped, except
for publishes.
Q: should publishes be totally async, even in the presence of
  disconnects? Ideally yes, but there is a danger of buffering vast
  volumes of messages during prolonged outages.

***** alternative design

Instead of keeping track of interesting channel actions, and not
dealing with commands because they are too hard, we provide on-connect
and on-disconnect hooks in which an API user can perform all the
necessary channel setup and resource declaration.

It is up to the users to ensure that their use of commands is safe,
i.e. doesn't suffer from the "stomp on resources created/deleted by
other connections" problem.

We could even conceivably prevent any use of "configuration" commands
outside the hooks.

****** Issue: names of private queues somehow need to be passed to app
perhaps return Maps of x and q names

**** TODO reliable, asynchronous, point-to-point conversation API

see [[file:unicast.org][unicast]]

- ultimately built on top of reliable connection/channel, but can also
  use an ordinary connection/channel

**** TODO HA version of the above

Q: Do we need full HA or would standby (plus maybe SAN) be sufficient?

creates queues on multiple nodes, subscribes to all of them, and acks
& throws away all received messages sent by the same sender with an id
less than or equal of an already received id. NB: the acking should
only happen after the original message has been ack'ed.

Q: how can we make this work reasonably efficient in a workload
distribution scenario?

PS: when there are multiple workers operating on a message stream,
they send replies the message ids are only unique per worker. That
means they need to identify themselves as a different *sender*, but
set the reply-to to the common address.

*** TODO algo collateral messaging API

** protocol

A -> B: msg(id)
A <- : notification(id, stage)
A <- : ...
B -> A: msg(in-reply-to:id, id)
B <- : notification(id, stage)
B <- : ...

NB: because delivery notifications are sent from multiple agents,
  message order cannot be guaranteed

*** TODO define collateral protocol
i.e. the stuff that sits on top of the above

*** TODO draw routing topology

*** TODO draw logical message flow
between C1, algo agent, C2

*** TODO sequence diagrams

*** TODO figure out messaging role of algo agent

Is it a proxy, in which case it will pass on messages with their
original from & message-id, or is it a full participant, in which case
in order to get the notifications to work the way we want it will need
to keep a mapping from message ids of the inbound messages to the
message ids of the corresponding outbound messages, so that it can
re-map the ids for notifications sent baxk by the recipient.

Let's assume it is a proxy and experiment with that.

** [[file:security.org][security]]
** detecting incorrect client behaviour

*** AMQP level
- check log for errors
  - how do we tie this back to users?
    - IP
    - use rabbitmqctl connection info; but must be quick

*** app level
- Algo agent error log/reporting, for app-level errors
  - perhaps just have another X to which errors are sent

** algo agent
** provisioning tool
provisions the queue(s) for every client
provisions record of all agreements

** web i/f
*** UI interactions
*** UI design
*** back-end
*** f/e - b/e communication

** testing
** deployment
** operational monitoring
** billing
** archiving
** recovering from app-level failures
manual intervention that needs to bring the state of the three
parties back in sync

** system upgrades
** scaling

*** DONE get some estimates of baseline, peak, growth
1M msg per day + 3m notifications

<20% of agreements generate a margin call on any given day

biggest client: 20k, planned to rise to 100k
avg: 1k, expected to rise
500 clients

msg size: few k

** IM

* possible rabbit extensions

** DONE allow suppression of queue declaration in Subscription ([[bug:21286]])
resolution: we actually ended up removing the use of Subscription
** DONE make IBasicProperties cloneable ([[bug:21271]])
** DONE add some AmqpTcpEndpoint constructors ([[bug:21531]])
ConnectionFactory has a whole bunch of overloads on CreateConnection,
that all end up creating an AmqpTcpEndpoint. It would be useful to
have these overloads on the AmqpTcpEndpoint constructor. Ideally we
would also remove all the ConnectionFactory.CreateConnection
overloads, but they are kinda convenient, so we should just make them
use the new constructors rather than removing them.
** DONE SSL ([[bug:19356]])
** DONE MSBuild ([[bug:21220]])

for .net client, since nant scares Windows people.

Apparently msbuild can work under mono too.

It is useful to have an msbuild, rather than just the dll in the GAC,
because it allows source-level debugging in VS.


** DONE name threads ([[bug:21748]])
** TODO generic protocol constants ([[bug:21537]])
There doesn't seem to be a protocol version agnostic way of getting
hold of protocol constants, even though most of them are common across
all versions.
** TODO allow sending of custom client_properties ([[bug:21949]])
** TODO display received client_properties ([[bug:21948]])
** TODO listing of queue consumers ([[bug:21963]], [[bug:21966]])
** TODO DL{Q,E} ([[bug:20337]])

For messages that get redelivered too often. See spec of basic.deliver
for some hints. The limit & dlq name would be configured on a
per-queue basis by specifying a property at queue creation time.

The redelivery counter will need to be persistent.

NB: the advantage of DLQs over re-publishing the message to a
different exchange is that all the meta information can be preserved
in the former case whereas we'd have to create a wrapper otherwise.

OTOH, DLEs would be far more flexible...
...and we already have invented a mechanism for preserving the meta
information - namely the exchange name - for alternate exchanges.

So let's go with DLEs instead.

** ulimits ([[bug:21384]])

- #conns per second (1st derivative of connection counter)
- #concurrent connections
- #channel creations per second (1st derivative of channel counter)
- #concurrent channels
- #commands per second (first derivative of command counter)
  - perhaps further broken down by command (ditto)
- amount of inbound data per second (first derivative of data volume counter)
NB: we don't say anything about queues here. That's because queues,
and the messages in them, aren't really owned by anybody.

For the rate-based limits, we may want to allow bursts of activity.

Since these are *u*limits, perhaps we should have a process per user
to keep track of these.

Should these limits be per cluster or per host?

** stats / accounting ([[bug:21387]])

Record stats on usage of system

- per user connection and channel counters
- per connection frame and data volume counters (in & out)
- per channel command counter (inbound and outbound)
  - perhaps further broken down by command
- per queue msg counter (in & out)

channels and connections reference users, so aggregation by user is
possible

While the entities about/in which we collect stats may be transient -
like connections and queues, and even users - the stats themselves
shouldn't be.

*** design

Stats are collected by a process (per VM, or perhaps per cluster)
which receives events from just two kinds of other processes:
connections and channels. These send information about themselves on
creation, and then supply stats periodically, on hibernation and on
termination. Termination events also include the close reason. There
are also some special events being generated by channels, namely the
creation of exchanges and queues.

Events always include the pid of the generating entity (i.e. the
connection or channel), and a timestamp.

*** connection events
creation event:
- user
- address & port
- peer address & port
- vhost
periodic event:
- socket stats
- channels opened/closed

We don't collect any stats on frames. I don't think it's worth doing
so, and the outbound info is hard to come by since it's only available
in the per-channel writers.

*** channel
creation event:
- connection_pid
- user, vhost (we need this in case the channel does not have an
  associated connection, e.g. when it's been created by the direct
  Erlang client)
periodic event:
- commands in/out
- {exchange, msg_count}
- {exchange, qpid, msg_count}
- {qpid, delivered, delivered_no_ack, get, get_no_ack, ack, purged}
special event #1:
- exchange_name
- exchange_props
special event #2:
- qpid
- queue_name
- queue_props

We don't collect per-consumer stats; I don't think it's worth it.

We don't include the binding key in routing stats. That's because in
general exchanges can route by information other than the binding key.

We could record command stats per type, but I don't think that's all
that useful, and if we did one may ask why the types shouldn't be
sub-divided further, e.g. active vs passive declares, etc.

Channels monitor qpids for which they have collected stats. When the
queues die they send a periodic event and then remove the dead queue's
stats from their state. That way the number of counters remains
bounded... except for the {exchange, msg_count} counters, but that
ought not to be a problem since the number of exchanges is typically
small.

Should we split the msg counts into persistent vs non-persistent?
What should be do about tx msgs and tx acks?

We don't collect stats in queues - everything that happens to a queue
can be inferred from the data collected by channels. That does mean
though that direct interactions with the queue, e.g. from a plugin,
are not recorded.

*** alternative design

Stats could be computed from more general events. These general events
would cover all interesting activities in an AMQP broker.

The design then neatly divides into the following areas
- event generation
- event distribution/collection/recording

Some questions:
- which events are interesting?
- how do we minimise the impact on performance?
  - filters that control which events are generated
  - limit / filter what information is included in events
  - pre-aggregate events
- how should we distribute events?
  - Erlang eventing, feeding into
    - log file
    - AMQP messaging

- how do we control distribution of events?

** queue browsing
The ability to look at the messages in a queue w/o consuming them.
- doesn't need to be a snapshot
- doesn't need to be in the protocol - all the use cases we can think
  of are for troubleshooting

advantages over consume + nack:
- doesn't prevent messages from getting delivered to consumers
- no re-ordering
- light-weight - little/no state to keep
* possible rabbit bugs

** WSAETIMEDOUT error in CreateConnection ([[bug:21201]])
...when establishing lots of connections and running tight publish
loops in them.
[[http://www.tomshardware.com/forum/170046-46-wsaetimedout][Google says]] that this is probably due to the connection timing
out. Apparently there are some registry settings and possible params
to tweak...though it turns out that registry setting has been
removed. "using an asynchronous client socket" (google for it) may
help, though I suspect all that's going to happen is that the error
gets reported asynchronously.

** exception indicating missing inbound heartbeat in .net client ([[bug:21203]])
This happens when the client is sending a lot of messages. One reason
this may happen is if the mainloop doesn't get enough cycles.
I tried increasing the Mainloop thread priority, but that didn't make
a difference.
Running the same test on a faster machine (quad core, rather than a VM
on some old dual core), made the problem go awway :(

** DONE when rabbit is very busy, rabbitmqctl can time out ([[bug:21202]])
with a {badrpc,timeout}

* resolved

** persistent vs non-persistent

With persistence we can shorten the duration for which a producer
needs to hang on to a message for GD - rather than having to wait
until the ultimate consumer confirms receipt, the producer just needs
to ensure it waits long enough for the message to get written to disk
by the broker.

** one user vs several

several, since it makes it easier to disable access. Also, if we only
had one username/password then if that gets compromised, potentially
allowing anybody to access the system, we'd have to ask all clients to
change their creds. Plus if we ever do add some more stats/accounting
functionality to rabbit then keying some of it on the user makes sense.

** number of queues per logical client

one - at the messaging level there is no distinction between requests,
replies and notifications.


* tasks
** protocol
*** HA layer
** refine security analysis
Aaron to get Mark to look at current doc and then see whether he needs
any help
** monitoring (rabbit and other)
Aaron to send Mark's current doc to Matthias for review
** deployment (rabbit and other)
Aaron to send Mark's current doc to Matthias for review
** algo dev infrastructure
** rabbit bugs and extensions
